# Wide Neural Networks Forget Less Catastrophically
## Skim Read
### Abstract
* Understanding of properties of neural networks that contribute to catastrophic forgetting is limited
* Focus on the model itself
* Width has a surprisingly important effect on forgetting

### Methodology
* Compares different models with the width of each model being varied

### Results
* Greater width tends to lead to better results

### Further Action
* Come back to this if I am going to go into detail about architecture later on
