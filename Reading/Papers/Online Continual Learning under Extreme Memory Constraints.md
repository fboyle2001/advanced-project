# Online Continual Learning under Extreme Memory Constraints
## Skim Read
### Abstract
* Distillation based method (subset of regularisation?)
* Proposes a memory-constrained format for continual learning

### Methodology
* Feels like they are going for extreme memory constraints to justify regularisation?
* Task-IL? 

### Results
* Not great result comparisons
* LwF is the only major one despite this being a 2020 paper!
* Very basic datasets, CIFAR-10
* Overall not good?

### Further Action
