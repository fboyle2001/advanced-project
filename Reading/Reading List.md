# Reading List
## Sources to find papers
- Lifelong learning workshop: https://nips.cc/Conferences/2021/Schedule?showEvent=21846

Feel like I need to do some more reading into architectural solutions

## Tuesday reading:
- CVPR 2020 Continual Learning in Computer Vision Competition: Approaches, Results, Current Challenges and Future Directions
- Incremental Deep Neural Network Learning using CCT
- Improved schemes for episodic memory-based lifelong learning
- Using hindsight to anchor past knowledge in continual learning
- The effectiveness of memory replay in large scale continual learning
- GAN memory with no forgetting
- Memory-efficient incremental learning through feature adaptation
- Online continual learning under extreme memory constraints

## Areas of Interest for Reading
### Meta-Learning
- Meta-learning representations for continual learning

### Arcitectural-based Models
- Find some

## Unread
### Old List:
- FearNet: Brain-Inspired Model for Incremental Learning
- Batch-level Experience Replay with Review for Continual Learning (won something at CVPR 2020)
- Towards robust evaluations of continual learning
- Continual learning for robotics: Definition, framework, learning strategies, opportunities and challenges
- Alleviating catastrophic forgetting using context-dependent gating and synaptic stabilization
- Lifelong Learning of Spatiotemporal Representations with Dual-Memory Recurrent Self-Organization
- Few-shot image classification with differentiable earth moverâ€™s distance and structured classifiers (deep?)
- Online Optimal Control with Linear Dynamics and Predictions: Algorithms and Regret Analysis (skim)
- Distilling the Knowledge in a Neural Network (skim?)
- End-to-End Incremental Learning (skim?)
- Large Scale Incremental Learning (skim?)
- Continual learning: A comparative study on how to defy forgetting in classification tasks
- Toward Open Set Recognition
- PODNet: Pooled Outputs Distillation for Small-Tasks Incremental Learning
- Online continual learning in image classification: An empirical survey (2022)
- Rainbow Memory: Continual Learning With a Memory of Diverse Samples
### Incremental Learning
- [LUCIR](http://openaccess.thecvf.com/content_CVPR_2019/html/Hou_Learning_a_Unified_Classifier_Incrementally_via_Rebalancing_CVPR_2019_paper.html)
- [Brain-inspired replay for continual learning with artificial neural networks](https://www.nature.com/articles/s41467-020-17866-2.pdf)
- [Incremental Deep Neural Network Learning using Classification Confidence Thresholding](https://arxiv.org/abs/2106.11437)
- [Automatically Discovering and Learning New Visual Categories with Ranking Statistics](https://arxiv.org/abs/2002.05714)
- [The Implicit Bias of Depth: How Incremental Learning Drives Generalization](http://www.openreview.net/pdf?id=H1lj0nNFwB)
- [Incremental few-shot learning via vector quantization in deep embedded space](https://openreview.net/pdf?id=3SV-ZePhnZM)
- [Continual lifelong learning with neural networks: A review](https://www.sciencedirect.com/science/article/pii/S0893608019300231) [[Continual lifelong learning with neural networks - A review]]
- [Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem](https://www.sciencedirect.com/science/article/abs/pii/S0079742108605368)
- [Continual Learning in Deep Networks: an Analysis of the Last Layer](https://arxiv.org/pdf/2106.01834.pdf)
- [Incremental Learning Through Deep Adaptation](https://openreview.net/pdf?id=ryj0790hb)
- [NetTailor: Tuning the Architecture, Not Just the Weights](https://arxiv.org/pdf/1907.00274v1.pdf)
- [Overcoming catastrophic forgetting in neural networks](https://arxiv.org/pdf/1612.00796.pdf)
- [Insights from the Future for Continual Learning](https://arxiv.org/pdf/2006.13748.pdf)
- [Encoder Based Lifelong Learning](https://openaccess.thecvf.com/content_iccv_2017/html/Rannen_Encoder_Based_Lifelong_ICCV_2017_paper.html)

### Network Pruning
- [ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression](https://arxiv.org/abs/1707.06342)
- [What is the State of Neural Network Pruning?](https://arxiv.org/pdf/2003.03033.pdf)
- [Importance Estimation for Neural Network Pruning](https://openaccess.thecvf.com/content_CVPR_2019/papers/Molchanov_Importance_Estimation_for_Neural_Network_Pruning_CVPR_2019_paper.pdf)

## Other Useful Resources
* [Transfer Learning](https://cs231n.github.io/transfer-learning/)
* [Incremental Learning PyTorch](https://github.com/arthurdouillard/incremental_learning.pytorch)
* [Open Source Continual Learning Projects](https://awesomeopensource.com/projects/continual-learning)
